{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lendo os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1       2       3        4        5       6        7       8  \\\n",
       "0  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.3001  0.14710  0.2419   \n",
       "1  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.0869  0.07017  0.1812   \n",
       "2  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.1974  0.12790  0.2069   \n",
       "3  11.42  20.38   77.58   386.1  0.14250  0.28390  0.2414  0.10520  0.2597   \n",
       "4  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.1980  0.10430  0.1809   \n",
       "\n",
       "         9  ...      22      23      24      25      26      27      28  \\\n",
       "0  0.07871  ...  184.60  2019.0  0.1622  0.6656  0.7119  0.2654  0.4601   \n",
       "1  0.05667  ...  158.80  1956.0  0.1238  0.1866  0.2416  0.1860  0.2750   \n",
       "2  0.05999  ...  152.50  1709.0  0.1444  0.4245  0.4504  0.2430  0.3613   \n",
       "3  0.09744  ...   98.87   567.7  0.2098  0.8663  0.6869  0.2575  0.6638   \n",
       "4  0.05883  ...  152.20  1575.0  0.1374  0.2050  0.4000  0.1625  0.2364   \n",
       "\n",
       "        29   30  y  \n",
       "0  0.11890  0.0  0  \n",
       "1  0.08902  0.0  0  \n",
       "2  0.08758  0.0  0  \n",
       "3  0.17300  NaN  0  \n",
       "4  0.07678  0.0  0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('breast_cancer_.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verificando se existem itens faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 32 columns):\n",
      "0     561 non-null float64\n",
      "1     565 non-null float64\n",
      "2     558 non-null float64\n",
      "3     564 non-null float64\n",
      "4     564 non-null float64\n",
      "5     560 non-null float64\n",
      "6     561 non-null float64\n",
      "7     566 non-null float64\n",
      "8     558 non-null float64\n",
      "9     566 non-null float64\n",
      "10    564 non-null float64\n",
      "11    559 non-null float64\n",
      "12    564 non-null float64\n",
      "13    560 non-null float64\n",
      "14    563 non-null float64\n",
      "15    566 non-null float64\n",
      "16    559 non-null float64\n",
      "17    566 non-null float64\n",
      "18    560 non-null float64\n",
      "19    566 non-null float64\n",
      "20    559 non-null float64\n",
      "21    566 non-null float64\n",
      "22    564 non-null float64\n",
      "23    563 non-null float64\n",
      "24    560 non-null float64\n",
      "25    564 non-null float64\n",
      "26    563 non-null float64\n",
      "27    562 non-null float64\n",
      "28    563 non-null float64\n",
      "29    565 non-null float64\n",
      "30    561 non-null float64\n",
      "y     569 non-null int64\n",
      "dtypes: float64(31), int64(1)\n",
      "memory usage: 142.4 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preenchando itens faltantes.\n",
    "Como observado na celula anterior existem alguns valores faltantes, portando a celula seguinte preenche os vlaores faltantes com a média da coluna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.where(pd.notna(df), df.mean(), axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0.627451</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1       2       3        4        5       6        7       8  \\\n",
       "0  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.3001  0.14710  0.2419   \n",
       "1  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.0869  0.07017  0.1812   \n",
       "2  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.1974  0.12790  0.2069   \n",
       "3  11.42  20.38   77.58   386.1  0.14250  0.28390  0.2414  0.10520  0.2597   \n",
       "4  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.1980  0.10430  0.1809   \n",
       "\n",
       "         9  ...      22      23      24      25      26      27      28  \\\n",
       "0  0.07871  ...  184.60  2019.0  0.1622  0.6656  0.7119  0.2654  0.4601   \n",
       "1  0.05667  ...  158.80  1956.0  0.1238  0.1866  0.2416  0.1860  0.2750   \n",
       "2  0.05999  ...  152.50  1709.0  0.1444  0.4245  0.4504  0.2430  0.3613   \n",
       "3  0.09744  ...   98.87   567.7  0.2098  0.8663  0.6869  0.2575  0.6638   \n",
       "4  0.05883  ...  152.20  1575.0  0.1374  0.2050  0.4000  0.1625  0.2364   \n",
       "\n",
       "        29        30  y  \n",
       "0  0.11890  0.000000  0  \n",
       "1  0.08902  0.000000  0  \n",
       "2  0.08758  0.000000  0  \n",
       "3  0.17300  0.627451  0  \n",
       "4  0.07678  0.000000  0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 32 columns):\n",
      "0     569 non-null float64\n",
      "1     569 non-null float64\n",
      "2     569 non-null float64\n",
      "3     569 non-null float64\n",
      "4     569 non-null float64\n",
      "5     569 non-null float64\n",
      "6     569 non-null float64\n",
      "7     569 non-null float64\n",
      "8     569 non-null float64\n",
      "9     569 non-null float64\n",
      "10    569 non-null float64\n",
      "11    569 non-null float64\n",
      "12    569 non-null float64\n",
      "13    569 non-null float64\n",
      "14    569 non-null float64\n",
      "15    569 non-null float64\n",
      "16    569 non-null float64\n",
      "17    569 non-null float64\n",
      "18    569 non-null float64\n",
      "19    569 non-null float64\n",
      "20    569 non-null float64\n",
      "21    569 non-null float64\n",
      "22    569 non-null float64\n",
      "23    569 non-null float64\n",
      "24    569 non-null float64\n",
      "25    569 non-null float64\n",
      "26    569 non-null float64\n",
      "27    569 non-null float64\n",
      "28    569 non-null float64\n",
      "29    569 non-null float64\n",
      "30    569 non-null float64\n",
      "y     569 non-null int64\n",
      "dtypes: float64(31), int64(1)\n",
      "memory usage: 142.4 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df.values[: , :-1], df.values[:, -1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definição dos modelos e padronização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbParam = {'estimator__learning_rate':[0.1, 0.05, 0.01], 'estimator__n_estimators':[50, 100, 200], 'estimator__max_depth':[3, 5, 7]}\n",
    "oParam = {'estimator__n_estimators':[50, 100, 200], 'estimator__max_depth':[3, 5, 7]}\n",
    "bParam = {'estimator__n_estimators':[50, 100, 200], 'estimator__base_estimator__max_depth':[3, 5, 7]}\n",
    "\n",
    "# Bagging com Decision Tree\n",
    "BDT = Pipeline([('transformer', StandardScaler()),\n",
    "                ('estimator', BaggingClassifier(base_estimator=DecisionTreeClassifier(random_state=42), oob_score=True, n_jobs=-1))])\n",
    "BDT = GridSearchCV(BDT, bParam, cv=3, scoring=['accuracy', 'precision', 'recall'], iid=True, return_train_score=True, refit=False)\n",
    "BDT.fit(X_train, y_train);\n",
    "\n",
    "# Random Forest\n",
    "RF = Pipeline([('transformer', StandardScaler()), ('estimator', RandomForestClassifier(random_state=42))])\n",
    "RF = GridSearchCV(RF, oParam, cv=3, scoring=['accuracy', 'precision', 'recall'], iid=True, return_train_score=True, refit=False)\n",
    "RF.fit(X_train, y_train);\n",
    "\n",
    "# Gradient Boosting\n",
    "GB = Pipeline([('transformer', StandardScaler()), ('estimator', GradientBoostingClassifier(random_state=42))])\n",
    "GB = GridSearchCV(GB, gbParam, cv=3, scoring=['accuracy', 'precision', 'recall'], iid=True, return_train_score=True, refit=False)\n",
    "GB.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliação do método Enseble BaggingClassifier -- Q1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observando os valores do BaggingClassifier com o Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>mean_test_precision</th>\n",
       "      <th>mean_test_recall</th>\n",
       "      <th>param_estimator__base_estimator__max_depth</th>\n",
       "      <th>param_estimator__n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.995604</td>\n",
       "      <td>0.993076</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.995604</td>\n",
       "      <td>0.993076</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.995604</td>\n",
       "      <td>0.993076</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.995604</td>\n",
       "      <td>0.993076</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.995604</td>\n",
       "      <td>0.993076</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.995604</td>\n",
       "      <td>0.993076</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.995604</td>\n",
       "      <td>0.993076</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.995604</td>\n",
       "      <td>0.993076</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.995604</td>\n",
       "      <td>0.993076</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_test_accuracy  mean_test_precision  mean_test_recall  \\\n",
       "0            0.995604             0.993076               1.0   \n",
       "1            0.995604             0.993076               1.0   \n",
       "2            0.995604             0.993076               1.0   \n",
       "3            0.995604             0.993076               1.0   \n",
       "4            0.995604             0.993076               1.0   \n",
       "5            0.995604             0.993076               1.0   \n",
       "6            0.995604             0.993076               1.0   \n",
       "7            0.995604             0.993076               1.0   \n",
       "8            0.995604             0.993076               1.0   \n",
       "\n",
       "  param_estimator__base_estimator__max_depth param_estimator__n_estimators  \n",
       "0                                          3                            50  \n",
       "1                                          3                           100  \n",
       "2                                          3                           200  \n",
       "3                                          5                            50  \n",
       "4                                          5                           100  \n",
       "5                                          5                           200  \n",
       "6                                          7                            50  \n",
       "7                                          7                           100  \n",
       "8                                          7                           200  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(BDT.cv_results_, columns=['mean_test_accuracy', 'mean_test_precision', 'mean_test_recall', 'param_estimator__base_estimator__max_depth', 'param_estimator__n_estimators'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que a maioria das combinações retornaram performances semelhantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observando os valores do Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>mean_test_precision</th>\n",
       "      <th>mean_test_recall</th>\n",
       "      <th>param_estimator__max_depth</th>\n",
       "      <th>param_estimator__n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.984615</td>\n",
       "      <td>0.976215</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.982418</td>\n",
       "      <td>0.976110</td>\n",
       "      <td>0.996507</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.978022</td>\n",
       "      <td>0.972607</td>\n",
       "      <td>0.993013</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.995604</td>\n",
       "      <td>0.993076</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.993407</td>\n",
       "      <td>0.989691</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.993407</td>\n",
       "      <td>0.989691</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.995604</td>\n",
       "      <td>0.993076</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.995604</td>\n",
       "      <td>0.993076</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.993407</td>\n",
       "      <td>0.989691</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_test_accuracy  mean_test_precision  mean_test_recall  \\\n",
       "0            0.984615             0.976215          1.000000   \n",
       "1            0.982418             0.976110          0.996507   \n",
       "2            0.978022             0.972607          0.993013   \n",
       "3            0.995604             0.993076          1.000000   \n",
       "4            0.993407             0.989691          1.000000   \n",
       "5            0.993407             0.989691          1.000000   \n",
       "6            0.995604             0.993076          1.000000   \n",
       "7            0.995604             0.993076          1.000000   \n",
       "8            0.993407             0.989691          1.000000   \n",
       "\n",
       "  param_estimator__max_depth param_estimator__n_estimators  \n",
       "0                          3                            50  \n",
       "1                          3                           100  \n",
       "2                          3                           200  \n",
       "3                          5                            50  \n",
       "4                          5                           100  \n",
       "5                          5                           200  \n",
       "6                          7                            50  \n",
       "7                          7                           100  \n",
       "8                          7                           200  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(RF.cv_results_, columns=['mean_test_accuracy', 'mean_test_precision', 'mean_test_recall', 'param_estimator__max_depth', 'param_estimator__n_estimators'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que na linha 7 e 3 foram obtidos os melhores resultados, utilizando os parâmetros\n",
    "3 ---> max_depth: 5 | n_estimators 50\n",
    "7 ---> max_depth: 7 | n_estimators 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obsevando os valores do gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>mean_test_precision</th>\n",
       "      <th>mean_test_recall</th>\n",
       "      <th>param_estimator__learning_rate</th>\n",
       "      <th>param_estimator__max_depth</th>\n",
       "      <th>param_estimator__n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.993407</td>\n",
       "      <td>0.993040</td>\n",
       "      <td>0.996497</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.993407</td>\n",
       "      <td>0.993040</td>\n",
       "      <td>0.996497</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.993407</td>\n",
       "      <td>0.993040</td>\n",
       "      <td>0.996497</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.991209</td>\n",
       "      <td>0.989583</td>\n",
       "      <td>0.996497</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.991209</td>\n",
       "      <td>0.989583</td>\n",
       "      <td>0.996497</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.991209</td>\n",
       "      <td>0.989583</td>\n",
       "      <td>0.996497</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.991209</td>\n",
       "      <td>0.989583</td>\n",
       "      <td>0.996497</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.991209</td>\n",
       "      <td>0.989583</td>\n",
       "      <td>0.996497</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.991209</td>\n",
       "      <td>0.989583</td>\n",
       "      <td>0.996497</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.993407</td>\n",
       "      <td>0.993040</td>\n",
       "      <td>0.996497</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.993407</td>\n",
       "      <td>0.993040</td>\n",
       "      <td>0.996497</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.993407</td>\n",
       "      <td>0.993040</td>\n",
       "      <td>0.996497</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.991209</td>\n",
       "      <td>0.989583</td>\n",
       "      <td>0.996497</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.991209</td>\n",
       "      <td>0.989583</td>\n",
       "      <td>0.996497</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.991209</td>\n",
       "      <td>0.989583</td>\n",
       "      <td>0.996497</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.991209</td>\n",
       "      <td>0.989583</td>\n",
       "      <td>0.996497</td>\n",
       "      <td>0.05</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.991209</td>\n",
       "      <td>0.989583</td>\n",
       "      <td>0.996497</td>\n",
       "      <td>0.05</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.991209</td>\n",
       "      <td>0.989583</td>\n",
       "      <td>0.996497</td>\n",
       "      <td>0.05</td>\n",
       "      <td>7</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.991209</td>\n",
       "      <td>0.989583</td>\n",
       "      <td>0.996497</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.991209</td>\n",
       "      <td>0.989583</td>\n",
       "      <td>0.996497</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.993407</td>\n",
       "      <td>0.993040</td>\n",
       "      <td>0.996497</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.991209</td>\n",
       "      <td>0.989583</td>\n",
       "      <td>0.996497</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.991209</td>\n",
       "      <td>0.989583</td>\n",
       "      <td>0.996497</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.991209</td>\n",
       "      <td>0.989583</td>\n",
       "      <td>0.996497</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.991209</td>\n",
       "      <td>0.989583</td>\n",
       "      <td>0.996497</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.991209</td>\n",
       "      <td>0.989583</td>\n",
       "      <td>0.996497</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.991209</td>\n",
       "      <td>0.989583</td>\n",
       "      <td>0.996497</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_test_accuracy  mean_test_precision  mean_test_recall  \\\n",
       "0             0.993407             0.993040          0.996497   \n",
       "1             0.993407             0.993040          0.996497   \n",
       "2             0.993407             0.993040          0.996497   \n",
       "3             0.991209             0.989583          0.996497   \n",
       "4             0.991209             0.989583          0.996497   \n",
       "5             0.991209             0.989583          0.996497   \n",
       "6             0.991209             0.989583          0.996497   \n",
       "7             0.991209             0.989583          0.996497   \n",
       "8             0.991209             0.989583          0.996497   \n",
       "9             0.993407             0.993040          0.996497   \n",
       "10            0.993407             0.993040          0.996497   \n",
       "11            0.993407             0.993040          0.996497   \n",
       "12            0.991209             0.989583          0.996497   \n",
       "13            0.991209             0.989583          0.996497   \n",
       "14            0.991209             0.989583          0.996497   \n",
       "15            0.991209             0.989583          0.996497   \n",
       "16            0.991209             0.989583          0.996497   \n",
       "17            0.991209             0.989583          0.996497   \n",
       "18            0.991209             0.989583          0.996497   \n",
       "19            0.991209             0.989583          0.996497   \n",
       "20            0.993407             0.993040          0.996497   \n",
       "21            0.991209             0.989583          0.996497   \n",
       "22            0.991209             0.989583          0.996497   \n",
       "23            0.991209             0.989583          0.996497   \n",
       "24            0.991209             0.989583          0.996497   \n",
       "25            0.991209             0.989583          0.996497   \n",
       "26            0.991209             0.989583          0.996497   \n",
       "\n",
       "   param_estimator__learning_rate param_estimator__max_depth  \\\n",
       "0                             0.1                          3   \n",
       "1                             0.1                          3   \n",
       "2                             0.1                          3   \n",
       "3                             0.1                          5   \n",
       "4                             0.1                          5   \n",
       "5                             0.1                          5   \n",
       "6                             0.1                          7   \n",
       "7                             0.1                          7   \n",
       "8                             0.1                          7   \n",
       "9                            0.05                          3   \n",
       "10                           0.05                          3   \n",
       "11                           0.05                          3   \n",
       "12                           0.05                          5   \n",
       "13                           0.05                          5   \n",
       "14                           0.05                          5   \n",
       "15                           0.05                          7   \n",
       "16                           0.05                          7   \n",
       "17                           0.05                          7   \n",
       "18                           0.01                          3   \n",
       "19                           0.01                          3   \n",
       "20                           0.01                          3   \n",
       "21                           0.01                          5   \n",
       "22                           0.01                          5   \n",
       "23                           0.01                          5   \n",
       "24                           0.01                          7   \n",
       "25                           0.01                          7   \n",
       "26                           0.01                          7   \n",
       "\n",
       "   param_estimator__n_estimators  \n",
       "0                             50  \n",
       "1                            100  \n",
       "2                            200  \n",
       "3                             50  \n",
       "4                            100  \n",
       "5                            200  \n",
       "6                             50  \n",
       "7                            100  \n",
       "8                            200  \n",
       "9                             50  \n",
       "10                           100  \n",
       "11                           200  \n",
       "12                            50  \n",
       "13                           100  \n",
       "14                           200  \n",
       "15                            50  \n",
       "16                           100  \n",
       "17                           200  \n",
       "18                            50  \n",
       "19                           100  \n",
       "20                           200  \n",
       "21                            50  \n",
       "22                           100  \n",
       "23                           200  \n",
       "24                            50  \n",
       "25                           100  \n",
       "26                           200  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(GB.cv_results_, columns=['mean_test_accuracy', 'mean_test_precision', 'mean_test_recall', 'param_estimator__learning_rate', 'param_estimator__max_depth', 'param_estimator__n_estimators'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Já para o GradientBoosting várias combinações se mostraram ter a mesma perfomance como nas linas: 0, 1, 2, 9, 10, 11 e 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Criando um modelo utilizando os melhores resultados obtidos no GridSearch utilizando todo o dataset\n",
    "\n",
    "O RandomForest e o Bagging com DecisionTree obtiveram os melhores resultados. Portanto irei escolher o RandomForest por ser mais rápido para mim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O StandardScalar foi ajustado para os dados de treino, e transformou os dados de treino.\n",
    "Para os dados de teste deverá apenas ser transformado por isso estou salvando o Scaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_trans = scaler.transform(X_train)\n",
    "X_test_trans = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 1.0, 1.0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(max_depth=5, n_estimators=50)\n",
    "rf.fit(X_train_trans, y_train)\n",
    "pred = rf.predict(X_test_trans)\n",
    "accuracy_score(y_test, pred), precision_score(y_test, pred), recall_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O modelo ficou bem melhor, com todos os dados, acertando todos os dados do conjunto de teste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criar uma rede MultiLayerPerceptron -- Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl = Sequential()\n",
    "mpl.add(Dense(32, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "mpl.add(Dense(1, activation='sigmoid'))\n",
    "mpl.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc']) # Add precision and recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Não sei muito bem como funciona as camadas, mas o problema é bem simples, portanto eu fiz apenas uma camada densa, e depois fiz uma outra camada, com saída 1, com a ativação sigmoid, que é voltada para valores entre 0 e 1. Usei o binary conssentropy como loss, pois estamos trabalhando com um problema binário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 32)                1024      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,057\n",
      "Trainable params: 1,057\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mpl.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 409 samples, validate on 46 samples\n",
      "Epoch 1/100\n",
      "409/409 [==============================] - 1s 3ms/sample - loss: 16.3134 - acc: 0.7457 - val_loss: 5.2787 - val_acc: 0.8478\n",
      "Epoch 2/100\n",
      "409/409 [==============================] - 0s 473us/sample - loss: 2.9213 - acc: 0.8240 - val_loss: 4.9563 - val_acc: 0.8261\n",
      "Epoch 3/100\n",
      "409/409 [==============================] - 0s 487us/sample - loss: 2.8535 - acc: 0.8191 - val_loss: 4.7246 - val_acc: 0.8478\n",
      "Epoch 4/100\n",
      "409/409 [==============================] - 0s 469us/sample - loss: 2.5020 - acc: 0.8264 - val_loss: 4.2892 - val_acc: 0.8478\n",
      "Epoch 5/100\n",
      "409/409 [==============================] - 0s 378us/sample - loss: 2.4459 - acc: 0.8117 - val_loss: 3.6631 - val_acc: 0.8696\n",
      "Epoch 6/100\n",
      "409/409 [==============================] - 0s 393us/sample - loss: 1.7772 - acc: 0.8435 - val_loss: 4.4390 - val_acc: 0.5435\n",
      "Epoch 7/100\n",
      "409/409 [==============================] - 0s 280us/sample - loss: 1.6005 - acc: 0.8337 - val_loss: 2.4897 - val_acc: 0.8696\n",
      "Epoch 8/100\n",
      "409/409 [==============================] - 0s 448us/sample - loss: 1.0762 - acc: 0.8680 - val_loss: 2.2648 - val_acc: 0.8261\n",
      "Epoch 9/100\n",
      "409/409 [==============================] - 0s 445us/sample - loss: 1.0099 - acc: 0.8729 - val_loss: 2.1938 - val_acc: 0.8261\n",
      "Epoch 10/100\n",
      "409/409 [==============================] - 0s 516us/sample - loss: 0.7543 - acc: 0.8973 - val_loss: 1.9375 - val_acc: 0.8478\n",
      "Epoch 11/100\n",
      "409/409 [==============================] - 0s 597us/sample - loss: 0.8468 - acc: 0.8826 - val_loss: 2.5011 - val_acc: 0.8261\n",
      "Epoch 12/100\n",
      "409/409 [==============================] - 0s 871us/sample - loss: 0.9200 - acc: 0.8753 - val_loss: 1.8018 - val_acc: 0.8696\n",
      "Epoch 13/100\n",
      "409/409 [==============================] - 0s 794us/sample - loss: 0.7043 - acc: 0.8875 - val_loss: 1.8297 - val_acc: 0.8478\n",
      "Epoch 14/100\n",
      "409/409 [==============================] - 0s 928us/sample - loss: 0.8812 - acc: 0.8655 - val_loss: 1.6803 - val_acc: 0.8696\n",
      "Epoch 15/100\n",
      "409/409 [==============================] - 0s 691us/sample - loss: 0.6790 - acc: 0.8900 - val_loss: 2.1730 - val_acc: 0.8043\n",
      "Epoch 16/100\n",
      "409/409 [==============================] - 0s 389us/sample - loss: 0.8027 - acc: 0.8631 - val_loss: 1.5566 - val_acc: 0.8478\n",
      "Epoch 17/100\n",
      "409/409 [==============================] - 0s 1ms/sample - loss: 0.7491 - acc: 0.8631 - val_loss: 1.5129 - val_acc: 0.8478\n",
      "Epoch 18/100\n",
      "409/409 [==============================] - 0s 819us/sample - loss: 0.5946 - acc: 0.8826 - val_loss: 1.4838 - val_acc: 0.8478\n",
      "Epoch 19/100\n",
      "409/409 [==============================] - 0s 599us/sample - loss: 0.5404 - acc: 0.8900 - val_loss: 1.4936 - val_acc: 0.8478\n",
      "Epoch 20/100\n",
      "409/409 [==============================] - 0s 859us/sample - loss: 0.5648 - acc: 0.8826 - val_loss: 1.4101 - val_acc: 0.8478\n",
      "Epoch 21/100\n",
      "409/409 [==============================] - 0s 1ms/sample - loss: 0.5594 - acc: 0.8973 - val_loss: 1.5295 - val_acc: 0.8478\n",
      "Epoch 22/100\n",
      "409/409 [==============================] - 0s 798us/sample - loss: 0.7292 - acc: 0.8533 - val_loss: 1.5939 - val_acc: 0.8261\n",
      "Epoch 23/100\n",
      "409/409 [==============================] - 0s 473us/sample - loss: 0.5054 - acc: 0.8826 - val_loss: 1.6850 - val_acc: 0.8261\n",
      "Epoch 24/100\n",
      "409/409 [==============================] - 0s 777us/sample - loss: 0.5470 - acc: 0.8729 - val_loss: 1.5546 - val_acc: 0.8261\n",
      "Epoch 25/100\n",
      "409/409 [==============================] - 0s 578us/sample - loss: 0.5084 - acc: 0.8998 - val_loss: 1.3145 - val_acc: 0.8478\n",
      "Epoch 26/100\n",
      "409/409 [==============================] - 0s 466us/sample - loss: 0.6484 - acc: 0.8460 - val_loss: 2.1416 - val_acc: 0.8043\n",
      "Epoch 27/100\n",
      "409/409 [==============================] - 0s 528us/sample - loss: 0.5263 - acc: 0.8729 - val_loss: 1.3554 - val_acc: 0.8478\n",
      "Epoch 28/100\n",
      "409/409 [==============================] - 0s 902us/sample - loss: 0.7633 - acc: 0.8509 - val_loss: 1.2618 - val_acc: 0.8478\n",
      "Epoch 29/100\n",
      "409/409 [==============================] - 0s 397us/sample - loss: 0.4507 - acc: 0.8949 - val_loss: 1.3770 - val_acc: 0.8478\n",
      "Epoch 30/100\n",
      "409/409 [==============================] - 0s 807us/sample - loss: 0.4829 - acc: 0.8875 - val_loss: 1.3409 - val_acc: 0.8696\n",
      "Epoch 31/100\n",
      "409/409 [==============================] - 0s 552us/sample - loss: 0.3481 - acc: 0.9218 - val_loss: 1.2419 - val_acc: 0.8913\n",
      "Epoch 32/100\n",
      "409/409 [==============================] - 0s 321us/sample - loss: 0.4620 - acc: 0.9046 - val_loss: 1.4769 - val_acc: 0.8261\n",
      "Epoch 33/100\n",
      "409/409 [==============================] - 0s 403us/sample - loss: 0.4345 - acc: 0.8924 - val_loss: 1.1558 - val_acc: 0.9130\n",
      "Epoch 34/100\n",
      "409/409 [==============================] - 0s 527us/sample - loss: 0.5480 - acc: 0.8704 - val_loss: 1.6154 - val_acc: 0.8043\n",
      "Epoch 35/100\n",
      "409/409 [==============================] - 0s 462us/sample - loss: 0.3793 - acc: 0.9120 - val_loss: 1.1981 - val_acc: 0.8478\n",
      "Epoch 36/100\n",
      "409/409 [==============================] - 0s 354us/sample - loss: 0.5446 - acc: 0.8802 - val_loss: 1.1200 - val_acc: 0.8478\n",
      "Epoch 37/100\n",
      "409/409 [==============================] - 0s 485us/sample - loss: 0.5265 - acc: 0.8680 - val_loss: 1.7742 - val_acc: 0.8043\n",
      "Epoch 38/100\n",
      "409/409 [==============================] - 0s 338us/sample - loss: 0.5162 - acc: 0.8778 - val_loss: 1.1208 - val_acc: 0.9348\n",
      "Epoch 39/100\n",
      "409/409 [==============================] - 0s 347us/sample - loss: 0.3732 - acc: 0.9046 - val_loss: 1.0610 - val_acc: 0.8478\n",
      "Epoch 40/100\n",
      "409/409 [==============================] - 0s 284us/sample - loss: 0.5233 - acc: 0.8729 - val_loss: 1.4732 - val_acc: 0.8261\n",
      "Epoch 41/100\n",
      "409/409 [==============================] - 0s 396us/sample - loss: 0.3254 - acc: 0.9267 - val_loss: 1.4169 - val_acc: 0.8261\n",
      "Epoch 42/100\n",
      "409/409 [==============================] - 0s 396us/sample - loss: 0.4343 - acc: 0.8998 - val_loss: 1.0365 - val_acc: 0.8478\n",
      "Epoch 43/100\n",
      "409/409 [==============================] - 0s 297us/sample - loss: 0.5140 - acc: 0.8778 - val_loss: 1.0819 - val_acc: 0.8478\n",
      "Epoch 44/100\n",
      "409/409 [==============================] - 0s 503us/sample - loss: 0.4036 - acc: 0.8826 - val_loss: 1.0490 - val_acc: 0.9348\n",
      "Epoch 45/100\n",
      "409/409 [==============================] - 0s 622us/sample - loss: 0.5221 - acc: 0.8704 - val_loss: 1.0244 - val_acc: 0.9130\n",
      "Epoch 46/100\n",
      "409/409 [==============================] - 0s 646us/sample - loss: 0.4937 - acc: 0.8778 - val_loss: 1.0371 - val_acc: 0.8478\n",
      "Epoch 47/100\n",
      "409/409 [==============================] - 0s 425us/sample - loss: 0.2986 - acc: 0.9242 - val_loss: 2.3089 - val_acc: 0.7609\n",
      "Epoch 48/100\n",
      "409/409 [==============================] - 0s 736us/sample - loss: 0.6444 - acc: 0.8240 - val_loss: 1.9347 - val_acc: 0.6957\n",
      "Epoch 49/100\n",
      "409/409 [==============================] - 0s 414us/sample - loss: 0.3273 - acc: 0.9071 - val_loss: 1.1974 - val_acc: 0.8696\n",
      "Epoch 50/100\n",
      "409/409 [==============================] - 0s 798us/sample - loss: 0.3984 - acc: 0.8949 - val_loss: 1.2372 - val_acc: 0.8696\n",
      "Epoch 51/100\n",
      "409/409 [==============================] - 0s 441us/sample - loss: 0.5451 - acc: 0.8826 - val_loss: 1.2932 - val_acc: 0.8261\n",
      "Epoch 52/100\n",
      "409/409 [==============================] - 0s 467us/sample - loss: 0.3836 - acc: 0.8998 - val_loss: 1.0851 - val_acc: 0.8478\n",
      "Epoch 53/100\n",
      "409/409 [==============================] - 0s 716us/sample - loss: 0.3172 - acc: 0.9120 - val_loss: 1.5828 - val_acc: 0.7174\n",
      "Epoch 54/100\n",
      "409/409 [==============================] - 0s 830us/sample - loss: 0.4833 - acc: 0.8753 - val_loss: 1.1365 - val_acc: 0.9130\n",
      "Epoch 55/100\n",
      "409/409 [==============================] - 0s 672us/sample - loss: 0.3744 - acc: 0.8802 - val_loss: 1.5880 - val_acc: 0.7391\n",
      "Epoch 56/100\n",
      "409/409 [==============================] - 0s 865us/sample - loss: 0.4025 - acc: 0.8998 - val_loss: 1.5253 - val_acc: 0.7391\n",
      "Epoch 57/100\n",
      "409/409 [==============================] - 0s 599us/sample - loss: 0.4992 - acc: 0.8900 - val_loss: 0.9333 - val_acc: 0.8478\n",
      "Epoch 58/100\n",
      "409/409 [==============================] - 0s 865us/sample - loss: 0.2322 - acc: 0.9413 - val_loss: 2.1113 - val_acc: 0.7609\n",
      "Epoch 59/100\n",
      "409/409 [==============================] - 0s 538us/sample - loss: 0.4061 - acc: 0.8900 - val_loss: 0.9088 - val_acc: 0.8478\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "409/409 [==============================] - 0s 928us/sample - loss: 0.4800 - acc: 0.8729 - val_loss: 0.9200 - val_acc: 0.8478\n",
      "Epoch 61/100\n",
      "409/409 [==============================] - 0s 482us/sample - loss: 0.2462 - acc: 0.9291 - val_loss: 0.9339 - val_acc: 0.9348\n",
      "Epoch 62/100\n",
      "409/409 [==============================] - 0s 441us/sample - loss: 0.6534 - acc: 0.8460 - val_loss: 1.1855 - val_acc: 0.8696\n",
      "Epoch 63/100\n",
      "409/409 [==============================] - 0s 813us/sample - loss: 0.2409 - acc: 0.9389 - val_loss: 0.9690 - val_acc: 0.8478\n",
      "Epoch 64/100\n",
      "409/409 [==============================] - 0s 448us/sample - loss: 0.4533 - acc: 0.8802 - val_loss: 0.8918 - val_acc: 0.8478\n",
      "Epoch 65/100\n",
      "409/409 [==============================] - 0s 722us/sample - loss: 0.5527 - acc: 0.8582 - val_loss: 0.8991 - val_acc: 0.9348\n",
      "Epoch 66/100\n",
      "409/409 [==============================] - 0s 708us/sample - loss: 0.2163 - acc: 0.9315 - val_loss: 1.8102 - val_acc: 0.7609\n",
      "Epoch 67/100\n",
      "409/409 [==============================] - 0s 372us/sample - loss: 0.3237 - acc: 0.9120 - val_loss: 1.8794 - val_acc: 0.6957\n",
      "Epoch 68/100\n",
      "409/409 [==============================] - 0s 898us/sample - loss: 0.6090 - acc: 0.8435 - val_loss: 0.8533 - val_acc: 0.9348\n",
      "Epoch 69/100\n",
      "409/409 [==============================] - 0s 796us/sample - loss: 0.3961 - acc: 0.8973 - val_loss: 1.3250 - val_acc: 0.8043\n",
      "Epoch 70/100\n",
      "409/409 [==============================] - 0s 786us/sample - loss: 0.3611 - acc: 0.9095 - val_loss: 0.9360 - val_acc: 0.8478\n",
      "Epoch 71/100\n",
      "409/409 [==============================] - 0s 682us/sample - loss: 0.1931 - acc: 0.9462 - val_loss: 0.8088 - val_acc: 0.8913\n",
      "Epoch 72/100\n",
      "409/409 [==============================] - 0s 515us/sample - loss: 0.4091 - acc: 0.8973 - val_loss: 1.0827 - val_acc: 0.8261\n",
      "Epoch 73/100\n",
      "409/409 [==============================] - 0s 750us/sample - loss: 0.2582 - acc: 0.9291 - val_loss: 1.6551 - val_acc: 0.6957\n",
      "Epoch 74/100\n",
      "409/409 [==============================] - 0s 365us/sample - loss: 0.2813 - acc: 0.9291 - val_loss: 0.7950 - val_acc: 0.8696\n",
      "Epoch 75/100\n",
      "409/409 [==============================] - 0s 872us/sample - loss: 0.5841 - acc: 0.8778 - val_loss: 0.8394 - val_acc: 0.9348\n",
      "Epoch 76/100\n",
      "409/409 [==============================] - 0s 543us/sample - loss: 0.2068 - acc: 0.9487 - val_loss: 1.6368 - val_acc: 0.6957\n",
      "Epoch 77/100\n",
      "409/409 [==============================] - 0s 907us/sample - loss: 0.3518 - acc: 0.9169 - val_loss: 0.7736 - val_acc: 0.8696\n",
      "Epoch 78/100\n",
      "409/409 [==============================] - 0s 555us/sample - loss: 0.5685 - acc: 0.8655 - val_loss: 0.8262 - val_acc: 0.8478\n",
      "Epoch 79/100\n",
      "409/409 [==============================] - 0s 862us/sample - loss: 0.2177 - acc: 0.9364 - val_loss: 0.7958 - val_acc: 0.9348\n",
      "Epoch 80/100\n",
      "409/409 [==============================] - 0s 725us/sample - loss: 0.3436 - acc: 0.8949 - val_loss: 1.3935 - val_acc: 0.7609\n",
      "Epoch 81/100\n",
      "409/409 [==============================] - 0s 764us/sample - loss: 0.4088 - acc: 0.8753 - val_loss: 0.7941 - val_acc: 0.9348\n",
      "Epoch 82/100\n",
      "409/409 [==============================] - 0s 393us/sample - loss: 0.2478 - acc: 0.9438 - val_loss: 2.0493 - val_acc: 0.7609\n",
      "Epoch 83/100\n",
      "409/409 [==============================] - 0s 466us/sample - loss: 0.4504 - acc: 0.8802 - val_loss: 0.8906 - val_acc: 0.9348\n",
      "Epoch 84/100\n",
      "409/409 [==============================] - 0s 799us/sample - loss: 0.2612 - acc: 0.9169 - val_loss: 0.8451 - val_acc: 0.8478\n",
      "Epoch 85/100\n",
      "409/409 [==============================] - 0s 408us/sample - loss: 0.3182 - acc: 0.8998 - val_loss: 0.7644 - val_acc: 0.9565\n",
      "Epoch 86/100\n",
      "409/409 [==============================] - 0s 702us/sample - loss: 0.3795 - acc: 0.9095 - val_loss: 0.7902 - val_acc: 0.8478\n",
      "Epoch 87/100\n",
      "409/409 [==============================] - 0s 839us/sample - loss: 0.2948 - acc: 0.9071 - val_loss: 0.8630 - val_acc: 0.8478\n",
      "Epoch 88/100\n",
      "409/409 [==============================] - 0s 730us/sample - loss: 0.2271 - acc: 0.9242 - val_loss: 0.7835 - val_acc: 0.8478\n",
      "Epoch 89/100\n",
      "409/409 [==============================] - 0s 685us/sample - loss: 0.3174 - acc: 0.8998 - val_loss: 0.7504 - val_acc: 0.8478\n",
      "Epoch 90/100\n",
      "409/409 [==============================] - 0s 571us/sample - loss: 0.3362 - acc: 0.8924 - val_loss: 0.9977 - val_acc: 0.8261\n",
      "Epoch 91/100\n",
      "409/409 [==============================] - 0s 607us/sample - loss: 0.2758 - acc: 0.9193 - val_loss: 0.7471 - val_acc: 0.8913\n",
      "Epoch 92/100\n",
      "409/409 [==============================] - 0s 283us/sample - loss: 0.3978 - acc: 0.8949 - val_loss: 0.7626 - val_acc: 0.8478\n",
      "Epoch 93/100\n",
      "409/409 [==============================] - 0s 731us/sample - loss: 0.1933 - acc: 0.9291 - val_loss: 1.0011 - val_acc: 0.8478\n",
      "Epoch 94/100\n",
      "409/409 [==============================] - 0s 462us/sample - loss: 0.3702 - acc: 0.9193 - val_loss: 1.9407 - val_acc: 0.6957\n",
      "Epoch 95/100\n",
      "409/409 [==============================] - 0s 803us/sample - loss: 0.3536 - acc: 0.9144 - val_loss: 0.8041 - val_acc: 0.9348\n",
      "Epoch 96/100\n",
      "409/409 [==============================] - 0s 709us/sample - loss: 0.3283 - acc: 0.9144 - val_loss: 0.7378 - val_acc: 0.8696\n",
      "Epoch 97/100\n",
      "409/409 [==============================] - 0s 824us/sample - loss: 0.1993 - acc: 0.9389 - val_loss: 0.7184 - val_acc: 0.9565\n",
      "Epoch 98/100\n",
      "409/409 [==============================] - 0s 419us/sample - loss: 0.1405 - acc: 0.9560 - val_loss: 2.4537 - val_acc: 0.5652\n",
      "Epoch 99/100\n",
      "409/409 [==============================] - 0s 598us/sample - loss: 0.4254 - acc: 0.9071 - val_loss: 0.7406 - val_acc: 0.8478\n",
      "Epoch 100/100\n",
      "409/409 [==============================] - 0s 824us/sample - loss: 0.2989 - acc: 0.9144 - val_loss: 0.9162 - val_acc: 0.8478\n"
     ]
    }
   ],
   "source": [
    "# como separando anteriormente, os dados de treino possuem 80% do dataset real,\n",
    "# separei 10% desses 80 para realizar a validação\n",
    "history = mpl.fit(X_train, y_train, epochs=100, validation_split=.1); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>0.140538</td>\n",
       "      <td>0.955990</td>\n",
       "      <td>2.453725</td>\n",
       "      <td>0.565217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.206822</td>\n",
       "      <td>0.948655</td>\n",
       "      <td>1.636848</td>\n",
       "      <td>0.695652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.193087</td>\n",
       "      <td>0.946210</td>\n",
       "      <td>0.808793</td>\n",
       "      <td>0.891304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>0.247838</td>\n",
       "      <td>0.943765</td>\n",
       "      <td>2.049324</td>\n",
       "      <td>0.760870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.232228</td>\n",
       "      <td>0.941320</td>\n",
       "      <td>2.111295</td>\n",
       "      <td>0.760870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.644376</td>\n",
       "      <td>0.823961</td>\n",
       "      <td>1.934744</td>\n",
       "      <td>0.695652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.921303</td>\n",
       "      <td>0.823961</td>\n",
       "      <td>4.956324</td>\n",
       "      <td>0.826087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.853500</td>\n",
       "      <td>0.819071</td>\n",
       "      <td>4.724637</td>\n",
       "      <td>0.847826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.445927</td>\n",
       "      <td>0.811736</td>\n",
       "      <td>3.663115</td>\n",
       "      <td>0.869565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>16.313365</td>\n",
       "      <td>0.745721</td>\n",
       "      <td>5.278747</td>\n",
       "      <td>0.847826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss       acc  val_loss   val_acc\n",
       "97   0.140538  0.955990  2.453725  0.565217\n",
       "75   0.206822  0.948655  1.636848  0.695652\n",
       "70   0.193087  0.946210  0.808793  0.891304\n",
       "81   0.247838  0.943765  2.049324  0.760870\n",
       "57   0.232228  0.941320  2.111295  0.760870\n",
       "..        ...       ...       ...       ...\n",
       "47   0.644376  0.823961  1.934744  0.695652\n",
       "1    2.921303  0.823961  4.956324  0.826087\n",
       "2    2.853500  0.819071  4.724637  0.847826\n",
       "4    2.445927  0.811736  3.663115  0.869565\n",
       "0   16.313365  0.745721  5.278747  0.847826\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).sort_values(by='acc', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A época onde foi obtida a melhor acurácia foi a 85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 455 samples\n",
      "455/455 [==============================] - 0s 395us/sample - loss: 0.3074 - acc: 0.9165\n"
     ]
    }
   ],
   "source": [
    "mpl.fit(X_train, y_train, epochs=1, callbacks=[history]); # espero que seja isso ;-;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Realizando o teste do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "114/1 [============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 114us/sample - loss: 0.2999 - acc: 0.8596\n"
     ]
    }
   ],
   "source": [
    "mpl.evaluate(X_test, y_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uau ele foi muito bem :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
